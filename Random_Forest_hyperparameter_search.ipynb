{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently shows for the three class case. Can be changed by removing the \"Undecided\" class name and mapping all\n",
    "# -1's to 0's\n",
    "class_names = ['Not Staying','Undecided', \"Staying\"]\n",
    "X_train= pd.read_excel('X_train.xlsx')\n",
    "X_test=pd.read_excel('X_test.xlsx')\n",
    "X_val=pd.read_excel('X_val.xlsx')\n",
    "y_train=pd.read_excel('y_train.xlsx')\n",
    "y_test=pd.read_excel('y_test.xlsx')\n",
    "y_val=pd.read_excel('y_val.xlsx')\n",
    "\n",
    "#y dataframes ending in 0 are for predicting post-ADSC retention\n",
    "#y dataframes ending in 1 are for predicting retention until retirement\n",
    "y_train0 = y_train['intention_beyond_commitment']\n",
    "y_train1 = y_train['intention_toward_retirement']\n",
    "y_val0 = y_val['intention_beyond_commitment']\n",
    "y_val1 = y_val['intention_toward_retirement']\n",
    "y_test0 = y_test['intention_beyond_commitment']\n",
    "y_test1 = y_test['intention_toward_retirement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing our data based on the distribution of the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns = X_val.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23eda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a Random Forest for each combination of estimators and depths for each type of retention of interest\n",
    "#Outputs an excel sheet of the results\n",
    "estimators = [1, 10, 100, 200, 500, 1000, 2000, 5000]\n",
    "depths = [1,2,3,4,5,6,7,8,9,10, 15, 20, 25, 50, 75]\n",
    "accs0 = []\n",
    "accs1=[]\n",
    "names=[]\n",
    "for n_estimators in estimators:\n",
    "    for max_depth in depths:\n",
    "        clf0 = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth)\n",
    "        clf0.fit(X_train, y_train0)\n",
    "        y_pred = clf0.predict(X_val)\n",
    "        accuracy0 = accuracy_score(y_val0, y_pred)\n",
    "        clf1 = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth)\n",
    "        clf1.fit(X_train, y_train1)\n",
    "        y_pred = clf1.predict(X_val)\n",
    "        accuracy1 = accuracy_score(y_val1, y_pred)\n",
    "        accs0.append(accuracy0)\n",
    "        accs1.append(accuracy1)\n",
    "        names.append(str(n_estimators) + str(max_depth))\n",
    "res_df = pd.DataFrame({\"Params\": names, 'Accuracy0': accs0, 'Accuracy1': accs1})\n",
    "print(res_df)\n",
    "res_df.to_excel(\"results_of_RF.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
