{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently shows for the two class case. Can be changed by adding the \"Undecided\" class name and \n",
    "#removing the mapping of all -1's to 0's\n",
    "class_names = ['Not Staying', \"Staying\"]\n",
    "X_train= pd.read_excel('BS_subset0_train_no_und.xlsx')\n",
    "#here we're using a subset of the training data found via BorutaSHAP\n",
    "#It will only keep the features found in that subset in all three sets\n",
    "X_test=pd.read_excel('X_test.xlsx')\n",
    "X_val=pd.read_excel('X_val.xlsx')\n",
    "X_val = X_val[X_train.columns.intersection(X_val.columns)]\n",
    "X_test = X_test[X_train.columns.intersection(X_test.columns)]\n",
    "y_train=pd.read_excel('y_train.xlsx')\n",
    "y_test=pd.read_excel('y_test.xlsx')\n",
    "y_val=pd.read_excel('y_val.xlsx')\n",
    "\n",
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)\n",
    "y_val.replace(-1, 0, inplace=True)\n",
    "\n",
    "\n",
    "#y dataframes ending in 0 are for predicting post-ADSC retention\n",
    "#y dataframes ending in 1 are for predicting retention until retirement\n",
    "y_train0 = y_train['intention_beyond_commitment']\n",
    "y_train1 = y_train['intention_toward_retirement']\n",
    "y_val0 = y_val['intention_beyond_commitment']\n",
    "y_val1 = y_val['intention_toward_retirement']\n",
    "y_test0 = y_test['intention_beyond_commitment']\n",
    "y_test1 = y_test['intention_toward_retirement']\n",
    "\n",
    "#Normalizing our data based on the distribution of the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns = X_val.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23eda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a RF using the subset of features found via BorutaSHAP for retention after ADSC\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 25)\n",
    "clf.fit(X_train, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c06fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating performance, currently shows for test, but can easily be switched for validation\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test0, y_pred)\n",
    "average_type = 'macro'  # Can be 'micro', 'macro', or 'weighted'\n",
    "precision_avg, recall_avg, f1_avg, _ = precision_recall_fscore_support(y_test0, y_pred, average=average_type)\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nOverall Accuracy ({average_type}): \", accuracy)\n",
    "print(f\"\\nOverall Precision ({average_type}): \", precision_avg)\n",
    "print(f\"Overall Recall ({average_type}): \", recall_avg)\n",
    "print(f\"Overall F1 Score ({average_type}): \", f1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test0, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Intention Toward Staying After Committment')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently shows for the three class case. Can be changed by removing the \"Undecided\" class name and mapping all\n",
    "# -1's to 0's\n",
    "class_names = ['Not Staying','Undecided', \"Staying\"]\n",
    "X_train = pd.read_excel('BS_subset1_train_with_und.xlsx')\n",
    "X_test=pd.read_excel('X_test.xlsx')\n",
    "X_val=pd.read_excel('X_val.xlsx')\n",
    "y_train=pd.read_excel('y_train.xlsx')\n",
    "y_test=pd.read_excel('y_test.xlsx')\n",
    "y_val=pd.read_excel('y_val.xlsx')\n",
    "#here we're using a subset of the training data found via BorutaSHAP\n",
    "#It will only keep the features found in that subset in all three sets\n",
    "X_val = X_val[X_train.columns.intersection(X_val.columns)]\n",
    "X_test = X_test[X_train.columns.intersection(X_test.columns)]\n",
    "y_train0 = y_train['intention_beyond_commitment']\n",
    "y_train1 = y_train['intention_toward_retirement']\n",
    "y_val0 = y_val['intention_beyond_commitment']\n",
    "y_val1 = y_val['intention_toward_retirement']\n",
    "y_test0 = y_test['intention_beyond_commitment']\n",
    "y_test1 = y_test['intention_toward_retirement']\n",
    "\n",
    "#Normalizing our data based on the distribution of the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns = X_val.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a RF using the subset of features found via BorutaSHAP for retention until retirement\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 15)\n",
    "clf.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating performance, currently shows for test, but can easily be switched for validation\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test1, y_pred)\n",
    "precision_avg, recall_avg, f1_avg, _ = precision_recall_fscore_support(y_test1, y_pred, average=average_type)\n",
    "\n",
    "print(f\"\\nOverall Accuracy ({average_type}): \", accuracy)\n",
    "print(f\"\\nOverall Precision ({average_type}): \", precision_avg)\n",
    "print(f\"Overall Recall ({average_type}): \", recall_avg)\n",
    "print(f\"Overall F1 Score ({average_type}): \", f1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5479560",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val1, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", cbar=False, square=True, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Intention Toward Staying Until Retirement')\n",
    "plt.show()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
